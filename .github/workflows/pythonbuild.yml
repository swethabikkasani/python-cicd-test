---
name: Python package
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
permissions:
  contents: read
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"
          
      - name: DisplayPythonversion
        run: python -c "import sys; print(sys.version)"
        
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build setuptools wheel pipenv
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          
      - name: Lint with Ruff
        run: |
          pip install ruff
          ruff --format=github --target-version=py39 .
        continue-on-error: true
        
      - name: Build package
        run: |
          pipenv lock
          python3 setup.py bdist_wheel
          ls -la
          
      - name: Deploy whl to AWS S3
        uses: qoqa/action-s3-cp@v1.1
        env:
           AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
           AWS_REGION: 'us-east-1'
           AWS_S3_PATH: '/PyBuilds/'
           FILE: '${{ github.workspace }}/dist/*.whl'
           
      - name: Deploy Python Starter file to S3
        uses: qoqa/action-s3-cp@v1.1
        env:
           AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
           AWS_REGION: 'us-east-1'
           AWS_S3_PATH: '/VirtualEnv/'
           FILE: '${{ github.workspace }}/app_entrypoint_spark.py'
           
      - name: Deploy Spark Summit sh file to S3
        uses: qoqa/action-s3-cp@v1.1
        env:
           AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
           AWS_REGION: 'us-east-1'
           AWS_S3_PATH: '/VirtualEnv/'
           FILE: '${{ github.workspace }}/scripts/start_py_script.sh'
           
      - name: Build Virtual Env
        run: |
          python3 -m venv pyspark_venvsource
          source pyspark_venvsource/bin/activate
          pip3 install -r requirements.txt
          pip install --no-cache-dir ${{ github.workspace }}/dist/*.whl
          pip3 install venv-pack
          venv-pack -f -o pyspark_venv.tar.gz
          
      - name: Deploy Virtual Env to S3
        uses: qoqa/action-s3-cp@v1.1
        env:
           AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
           AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
           AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
           AWS_REGION: 'us-east-1'
           AWS_S3_PATH: '/VirtualEnv/'
           FILE: '${{ github.workspace }}/pyspark_venv.tar.gz'
           
             
